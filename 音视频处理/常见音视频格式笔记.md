参考

- 1.http://blog.csdn.net/vblittleboy/article/details/6174500#MPEG-1
- 2.https://mp.weixin.qq.com/s?__biz=MzI2OTQxMTM4OQ==&mid=2247484548&idx=1&sn=651fc0d6c6b7e57e3fea5836a82addff&chksm=eae1f1d6dd9678c0a94b02c8047366485906b0da5687c34421e6e1d92216fd5ddc50d09f6d8e#rd

--------

## 视频编码

视频编码有两套标准，国际电信联盟（ITU）、ISO的MPEG标准。
ITU：
ISO MPEG：

#### **AAC**

在 MPEG-2 上开发的一种新的音频编码，和传统的 MPEG Audio 不兼容，它的质量理论上高于 MP3，并且支持多声道。在 96kbps 的码率范围内就能接近 CD 音质，比 MP3 更加适合地码率传输。AAC 已经作为 MPEG-4 标准的音频编码，当然 MPEG-4 Audio 还有其他多种音频编码。

AAC（Advanced Audio Coding），中文名：高级[音频](https://baike.baidu.com/item/%E9%9F%B3%E9%A2%91)[编码](https://baike.baidu.com/item/%E7%BC%96%E7%A0%81/80092)，出现于1997年，基于[MPEG-2](https://baike.baidu.com/item/MPEG-2)的音频编码技术。由Fraunhofer IIS、[杜比实验室](https://baike.baidu.com/item/%E6%9D%9C%E6%AF%94%E5%AE%9E%E9%AA%8C%E5%AE%A4)、[AT&T](https://baike.baidu.com/item/AT%26T)、[Sony](https://baike.baidu.com/item/Sony)等公司共同开发，目的是取代[MP3](https://baike.baidu.com/item/MP3/23904)格式。2000年，[MPEG-4](https://baike.baidu.com/item/MPEG-4)标准出现后，AAC重新集成了其特性，加入了SBR技术和PS技术，为了区别于传统的MPEG-2 AAC又称为[MPEG-4](https://baike.baidu.com/item/MPEG-4) AAC。

#### **H.264**

也就是前面提到的 MPEG-4AVC。H.264是由ISO/IEC与ITU-T组成的联合视频组(JVT)制定的新一代视频压缩编码标准。在ISO/IEC中该标准命名为AVC(Advanced Video Coding)，作为MPEG-4标准的第10个选项；在ITU-T中正式命名为H.264标准。

##  **什么是音视频编码格式？什么是音视频封装格式？**

常见的AVI、RMVB、MKV、ASF、WMV、MP4、3GP、FLV等文件其实只能算是一种封装标准。

一个完整的视频文件是由音频和视频2部分组成的。H264、Xvid等就是视频编码格式，MP3、AAC等就是音频编码格式。

例如：将一个Xvid视频编码文件和一个MP3视频编码文件按AVI封装标准封装以后，就得到一个AVI后缀的视频文件，这个就是我们常见的AVI视频文件了。

由于很多种视频编码文件、音频编码文件都符合AVI封装要求，则意味着即使是AVI后缀，也可能里面的具体编码格式不同。因此出现在一些设备上，同是AVI后缀文件，一些能正常播放，还有一些就无法播放。

同样的情况也存在于其他容器格式。即使RMVB、WMV等也不例外，事实上，很多封装容器对音频编码和视频编码的组合方式放的很开，如AVI还可以使用H.264+AAC组合，可以在具体使用中自己体会。尤其是MKV封装容器，基本无论什么样的组合都可以！但一般MKV用的最多的就是H.264+AAC组合，此组合文件体积最小，清晰度最高。因此网上很多MKV视频都是高清晰度的。

因此，视频转换需要设置的本质就是：A设置需要的视频编码、B设置需要的音频编码、C选择需要的容器封装。一个完整的视频转换设置都至少包括了上面3个步骤。

## **平时说的软解和硬解，具体是什么？**

硬解就是硬件解码，指利用GPU来部分代替CPU进行解码，软解就是软件解码，指利用软件让CPU来进行解码。两者的具体区别如下所示：

硬解码：是将原来全部交由CPU来处理的视频数据的一部分交由GPU来做，而GPU的并行运算能力要远远高于CPU，这样可以大大的降低对CPU的负载，CPU的占用率较低了之后就可以同时运行一些其他的程序了，当然，对于较好的处理器来说，比如i5 2320，或者AMD 任何一款四核心处理器来说，硬解和软件的区别只是个人偏好问题了吧。　　

软解码：即通过软件让CPU来对视频进行解码处理；而硬解码：指不借助于CPU，而通过专用的子卡设备来独立完成视频解码任务。曾经的VCD/DVD解压卡、视频压缩卡等都隶属于硬解码这个范畴。而现如今，要完成高清解码已经不再需要额外的子卡，因为硬解码的模块已经被整合到显卡GPU的内部，所以目前的主流显卡（集显）都能够支持硬解码技术。

##  **常见的直播协议有哪些？之间有什么区别？**

常见的直播协议有三种 RTMP、HLS、FLV...

1、RTMP：real time messaging protocol~实时传输协议，RTMP协议比较全能，既可以用来推送又可以用来直播，其核心理念是将大块的视频帧和音频帧“剁碎”，然后以小数据包的形式在互联网上进行传输，而且支持加密，因此隐私性相对比较理想，但拆包组包的过程比较复杂，所以在海量并发时也容易出现一些不可预期的稳定性问题。
2、FLV：FLV协议由Adobe公司主推，格式极其简单，只是在大块的视频帧和音视频头部加入一些标记头信息，由于这种极致的简洁，在延迟表现和大规模并发方面都很成熟。唯一的不足就是在手机浏览器上的支持非常有限，但是用作手机端APP直播协议却异常合适。
3、HLS：苹果原生：HTTP Live Streaming，遵循的是 HTTP 超文本传输协议，端口号8080，将视频分成5-10秒的视频小分片，然后用m3u8索引表进行管理，由于客户端下载到的视频都是5-10秒的完整数据，故视频的流畅性很好，但也同样引入了很大的延迟（HLS的一般延迟在10-30s左右）。

##  **何为Nginx？有什么特点？**

Nginx 是一个遵循 HTTP 协议的服务器！内存占用少，并发能力强！ 还有等等的优点，可自行google

##  **m3u8构成是？直播中m3u8、ts如何实时更新？**

是HLS的两个部分，

m3u8是一个索引地址/播放列表，通过FFmpeg将本地的xxx.mp4进行切片处理，生成m3u8播放列表（索引文件）和N多个 .ts文件，并将其（m3u8、N个ts）放置在本地搭建好的webServer服务器的指定目录下，我就可以得到一个可以实时播放的网址，我们把这个m3u8地址复制到 VLC 上就可以实时观看！
在 HLS 流下，本地视频被分割成一个一个的小切片，一般10秒一个，这些个小切片被 m3u8管理，并且随着终端的FFmpeg 向本地拉流的命令而实时更新，影片进度随着拉流的进度而更新，播放过的片段不在本地保存，自动删除，直到该文件播放完毕或停止，ts 切片会相应的被删除，流停止，影片不会立即停止，影片播放会滞后于拉流一段时间， 

- [HLS－m3u8播放列表和ts切片（2）](http://www.jianshu.com/p/f71e1b82e043)
- [用ffmpeg 把mp4文件转为ts文件并生成m3u8列表](http://blog.csdn.net/jookers/article/details/21694957)
- [FFmpeg参数命令](http://www.jianshu.com/p/eda9c444adbe)
- [hls之m3u8、ts流格式详解](http://blog.csdn.net/allnlei/article/details/53005350)

指令类似
```
ffmpeg -i XXX.mp4 -c:v libx264 -c:a copy -f hls XXX.m3u8
```

##  **PCM**

PCM [脉冲编码调制](https://baike.baidu.com/item/%E8%84%89%E5%86%B2%E7%BC%96%E7%A0%81%E8%B0%83%E5%88%B6)是Pulse Code Modulation的缩写。脉冲编码调制是数字通信的[编码方式](https://baike.baidu.com/item/%E7%BC%96%E7%A0%81%E6%96%B9%E5%BC%8F)之一。

##  **YUV、RGB**

http://www.cnblogs.com/silence-hust/p/4465354.html
